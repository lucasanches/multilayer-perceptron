{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6385f06",
   "metadata": {},
   "source": [
    "# Classe MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf22f212",
   "metadata": {},
   "source": [
    "## Importando os módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbb0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b957c8d0",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18976cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, n_epochs, n_features, n_hidden, n_classes, activation, learning_rate, patience, seed=None):        # iniciando a rede neural e definindo configurações iniciais\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = learning_rate\n",
    "        self.n_classes = n_classes\n",
    "        self.patience = patience\n",
    "\n",
    "        self.best_loss = float('inf')\n",
    "        self.no_improvement_count = 0\n",
    "        self.stop_training = False\n",
    "\n",
    "        # Camada de entrada\n",
    "        self.input_layer = nn.Linear(n_features, n_hidden[0])\n",
    "\n",
    "        # Camadas escondidas\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "\n",
    "        for layer in range(len(n_hidden) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(n_hidden[layer], n_hidden[layer + 1]))\n",
    "\n",
    "        # Camada de saída\n",
    "        self.output_layer = nn.Linear(n_hidden[-1], n_classes)\n",
    "        \n",
    "        # Função de ativação das camadas escondidas\n",
    "        self.activation_name = activation\n",
    "\n",
    "        if activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise ValueError(\"Função de ativação não reconhecida. Escolha entre 'relu' ou 'tanh'.\")\n",
    "        \n",
    "    \n",
    "    def forward(self, x):                                                   # definindo como os dados passam pela rede neural\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.activation(layer(x))\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def check_early_stop(self, val_loss):\n",
    "\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.no_improvement_count = 0\n",
    "        else:\n",
    "            self.no_improvement_count += 1\n",
    "            if self.no_improvement_count >= self.patience:\n",
    "                self.stop_training = True\n",
    "                print(\"Parando treinamento por early stopping.\")\n",
    "\n",
    "    \n",
    "    def compute_accuracy(self, output, y_true, n_classes):\n",
    "        if n_classes == 1:\n",
    "            preds = (output > 0).float()\n",
    "        else:\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            if y_true.ndim > 1:\n",
    "                y_true = torch.argmax(y_true, dim=1)\n",
    "\n",
    "        correct = (preds == y_true).float().sum()\n",
    "        total = y_true.shape[0]\n",
    "\n",
    "        return (correct / total).item()\n",
    "\n",
    "\n",
    "    def train_model(self, X_train, X_val, y_train, y_val, optimizer):                                       # definindo a função de treinamento\n",
    "\n",
    "        # Definindo o otimizador\n",
    "        if optimizer == \"sgd\":\n",
    "            self.optimizer = torch.optim.SGD(self.parameters(), lr = self.lr)\n",
    "        elif optimizer == \"adam\":\n",
    "            self.optimizer = torch.optim.Adam(self.parameters(), lr = self.lr)\n",
    "        else:\n",
    "            raise ValueError(\"Otimizador não reconhecido. Escolha entre 'sgd' ou 'adam'.\")\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss() if self.n_classes == 1 else nn.CrossEntropyLoss()        # função de perda diferente para classificação binária ou multiclasse \n",
    "\n",
    "        loss_train_list = []\n",
    "        loss_valid_list = []\n",
    "        accuracy_train_list = []\n",
    "        accuracy_valid_list = []\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self.train()\n",
    "\n",
    "            # Forward\n",
    "            output = self.forward(X_train)\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(output, y_train)\n",
    "            loss_train_list.append(loss.item())\n",
    "\n",
    "            # Backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Validação\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                val_output = self.forward(X_val)\n",
    "                val_loss = criterion(val_output, y_val) \n",
    "                loss_valid_list.append(val_loss.item())\n",
    "\n",
    "            # Acurácia\n",
    "            accuracy_train = self.compute_accuracy(output, y_train, self.n_classes)\n",
    "            accuracy_valid = self.compute_accuracy(val_output, y_val, self.n_classes)\n",
    "            accuracy_train_list.append(accuracy_train)\n",
    "            accuracy_valid_list.append(accuracy_valid)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs} - Train Loss: {loss.item():.4f} - Val Loss: {val_loss:.4f} - Train Accuracy: {accuracy_train:.4f} - Val Accuracy: {accuracy_valid:.4f}\")\n",
    "\n",
    "            # Early Stopping\n",
    "            self.check_early_stop(val_loss.item())\n",
    "\n",
    "            if self.stop_training:\n",
    "                break\n",
    "\n",
    "\n",
    "        return loss_train_list, loss_valid_list, accuracy_train_list, accuracy_valid_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
